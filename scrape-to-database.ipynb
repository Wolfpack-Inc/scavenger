{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-11T17:35:02.206632Z",
     "start_time": "2019-10-11T17:35:02.203006Z"
    }
   },
   "outputs": [],
   "source": [
    "import os, os.path\n",
    "from PIL import Image\n",
    "import requests\n",
    "from io import BytesIO\n",
    "import xml.etree.ElementTree as ET\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import imagehash\n",
    "\n",
    "SCRAPE_DIR = '.scrape_output'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Steps to fetch the xml files\n",
    "1. Install `pip install oaiharvest`\n",
    "2. Create a folder in this repo called '.scrape_output'\n",
    "3. `cd .scrape_output`\n",
    "4. Run the following command: `oai-harvest --set=Beelddocument --metadataPrefix=ese https://denbosch.hosting.deventit.net/atlantispubliek/oai.axd` (This may take a while)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-11T17:35:02.719875Z",
     "start_time": "2019-10-11T17:35:02.716419Z"
    }
   },
   "source": [
    "### Test code to get the format of the xml file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-11T17:36:33.477067Z",
     "start_time": "2019-10-11T17:36:33.465439Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tree = ET.parse('.scrape_output/14433440.ese.xml')\n",
    "root = tree.getroot()\n",
    "\n",
    "items = []\n",
    "\n",
    "for child in root:\n",
    "    prefix, has_namespace, postfix = child.tag.partition('}')\n",
    "    items.append({\n",
    "        'key': postfix,\n",
    "        'value': child.text\n",
    "    })\n",
    "\n",
    "pd.DataFrame(items)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a list of the XML files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-11T17:38:10.587619Z",
     "start_time": "2019-10-11T17:38:10.370397Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.scrape_output/104915350.ese.xml',\n",
       " '.scrape_output/104915448.ese.xml',\n",
       " '.scrape_output/104915560.ese.xml']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_xml_files = [SCRAPE_DIR + '/' + name for name in os.listdir(SCRAPE_DIR)]\n",
    "image_xml_files[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loop through the images and transform them into a dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-11T17:40:23.813746Z",
     "start_time": "2019-10-11T17:40:23.806436Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "44892it [4:18:16,  2.90it/s] \n"
     ]
    }
   ],
   "source": [
    "##### from tqdm import tqdm\n",
    "images = []\n",
    "\n",
    "# xml namespace\n",
    "ns = {\n",
    "    'dc': 'http://purl.org/dc/elements/1.1/',\n",
    "    'europeana': 'http://www.europeana.eu/schemas/ese/',\n",
    "    'dcterms': 'http://purl.org/dc/terms/'\n",
    "}\n",
    "\n",
    "# No image hash\n",
    "no_img = '00ff6767777f8300'\n",
    "\n",
    "for idx, image_xml in tqdm(enumerate(image_xml_files[:])):\n",
    "    \n",
    "    # Dictionary to store the image attributes\n",
    "    image_attribs = {}\n",
    "    \n",
    "    # Default to usable picture\n",
    "    image_attribs['usable'] = 1\n",
    "    \n",
    "    # Parse as xml\n",
    "    tree = ET.parse(image_xml)\n",
    "    \n",
    "    # Get the root of the tree\n",
    "    root = tree.getroot()\n",
    "    \n",
    "    # Location\n",
    "    coverage = root.find('dc:coverage', ns)\n",
    "    \n",
    "    if coverage == None:\n",
    "        continue\n",
    "    else:\n",
    "        coverage = coverage.text.split(';')\n",
    "        if (coverage[0] != \"'s-Hertogenbosch\") | (coverage[1] == ''):\n",
    "            image_attribs['usable'] = 0\n",
    "        \n",
    "    street = coverage[1]\n",
    "    image_attribs['street'] = street\n",
    "        \n",
    "    # Medium\n",
    "    medium = root.find('dcterms:medium', ns)\n",
    "    \n",
    "    # Make sure the image is a photo\n",
    "    if medium == None:\n",
    "        continue\n",
    "    elif medium.text != 'Foto':\n",
    "        image_attribs['usable'] = 0\n",
    "        \n",
    "    # Image url\n",
    "    image_url = root.find('europeana:object', ns).text\n",
    "    \n",
    "    # Check if the image exists\n",
    "    # Only run if the rest of is valid\n",
    "    if image_attribs['usable'] != 0:\n",
    "        try:\n",
    "            response = requests.get(image_url)\n",
    "            image = Image.open(BytesIO(response.content))\n",
    "            hasj = str(imagehash.average_hash(image))\n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "        # If there is no image\n",
    "        if hasj == no_img:\n",
    "            image_attribs['usable'] = 0\n",
    "\n",
    "    # Image url\n",
    "    image_attribs['url'] = image_url\n",
    "    \n",
    "    # Get the title\n",
    "    image_attribs['title'] = root.find('dc:title', ns).text.strip()\n",
    "            \n",
    "    # Date\n",
    "    if root.find('dc:date', ns).text == None or len(root.find('dc:date', ns).text[-4:]) < 4 or '/' in root.find('dc:date', ns).text[-4:]:\n",
    "        image_attribs['year'] = None\n",
    "    else: \n",
    "        image_attribs['year'] = root.find('dc:date', ns).text[-4:]\n",
    "        \n",
    "    # Add to list\n",
    "    images.append(image_attribs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-11T17:40:24.537459Z",
     "start_time": "2019-10-11T17:40:24.528787Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>street</th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>usable</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Muntelplein</td>\n",
       "      <td>Arbeiderswoningen van woningbouwvereniging mgr...</td>\n",
       "      <td>http://denbosch.hosting.deventit.net/HttpHandl...</td>\n",
       "      <td>1</td>\n",
       "      <td>1930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td>Arbeiderswoningen van woningbouwvereniging mgr...</td>\n",
       "      <td>http://denbosch.hosting.deventit.net/HttpHandl...</td>\n",
       "      <td>0</td>\n",
       "      <td>1930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td>Arbeiderswoningen van woningbouwvereniging mgr...</td>\n",
       "      <td>http://denbosch.hosting.deventit.net/HttpHandl...</td>\n",
       "      <td>0</td>\n",
       "      <td>1930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td>Arbeiderswoningen van woningbouwvereniging mgr...</td>\n",
       "      <td>http://denbosch.hosting.deventit.net/HttpHandl...</td>\n",
       "      <td>0</td>\n",
       "      <td>1930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Citadellaan</td>\n",
       "      <td>Woningen ontworpen door architect Jan van den ...</td>\n",
       "      <td>http://denbosch.hosting.deventit.net/HttpHandl...</td>\n",
       "      <td>1</td>\n",
       "      <td>1930</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        street                                              title  \\\n",
       "0  Muntelplein  Arbeiderswoningen van woningbouwvereniging mgr...   \n",
       "1               Arbeiderswoningen van woningbouwvereniging mgr...   \n",
       "2               Arbeiderswoningen van woningbouwvereniging mgr...   \n",
       "3               Arbeiderswoningen van woningbouwvereniging mgr...   \n",
       "4  Citadellaan  Woningen ontworpen door architect Jan van den ...   \n",
       "\n",
       "                                                 url  usable  year  \n",
       "0  http://denbosch.hosting.deventit.net/HttpHandl...       1  1930  \n",
       "1  http://denbosch.hosting.deventit.net/HttpHandl...       0  1930  \n",
       "2  http://denbosch.hosting.deventit.net/HttpHandl...       0  1930  \n",
       "3  http://denbosch.hosting.deventit.net/HttpHandl...       0  1930  \n",
       "4  http://denbosch.hosting.deventit.net/HttpHandl...       1  1930  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(images)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle('images.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mysql-connector==2.1.7\n",
      "  Downloading https://files.pythonhosted.org/packages/14/4f/6a2f92061e6e011ac47c43ad5a1999ed7dffaee75bd69713faa94caa6bb2/mysql-connector-2.1.7.tar.gz (11.8MB)\n",
      "Building wheels for collected packages: mysql-connector\n",
      "  Building wheel for mysql-connector (setup.py): started\n",
      "  Building wheel for mysql-connector (setup.py): finished with status 'done'\n",
      "  Stored in directory: C:\\Users\\Jules\\AppData\\Local\\pip\\Cache\\wheels\\af\\91\\0e\\741c42023be0a2187955bdae14d74bd0e6baf5a1632404cf9b\n",
      "Successfully built mysql-connector\n",
      "Installing collected packages: mysql-connector\n",
      "  Found existing installation: mysql-connector 2.2.9\n",
      "    Uninstalling mysql-connector-2.2.9:\n",
      "      Successfully uninstalled mysql-connector-2.2.9\n",
      "Successfully installed mysql-connector-2.1.7\n"
     ]
    }
   ],
   "source": [
    "!pip install mysql-connector==2.1.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dataframe into MySQL\n",
    "import sqlalchemy\n",
    "database_username = 'remote'\n",
    "database_password = 'EtrPCEc0jt'\n",
    "database_ip       = '165.22.199.122'\n",
    "database_name     = 'scavenger'\n",
    "database_connection = sqlalchemy.create_engine('mysql+mysqlconnector://{0}:{1}@{2}/{3}'.\n",
    "                                               format(database_username, database_password, \n",
    "                                                      database_ip, database_name))\n",
    "df.to_sql(con=database_connection, name='images', if_exists='replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "# HERE app_id & app_code\n",
    "APP_ID = 'oidKwC98hLcIQBaboIwS'\n",
    "APP_CODE = 'G6gKSvk45y4fF14hwpIeYg'\n",
    "\n",
    "# Function that collects multiple location-coordinates of a single street\n",
    "def get_location(streetname):\n",
    "    '''Returns list of latitude and longitude coordinates for a given street'''\n",
    "    \n",
    "    if streetname == '':\n",
    "        return None\n",
    "    \n",
    "    url = 'https://geocoder.api.here.com/6.2/geocode.json?app_id=' + APP_ID + '&app_code=' + APP_CODE + '&searchtext='\n",
    "\n",
    "    r = requests.get(url + streetname + \", 's-Hertogenbosch\").json()\n",
    "    \n",
    "    if r['Response']['View'] != []:\n",
    "        \n",
    "        loc_data = r['Response']['View'][0]['Result'][0]['Location']\n",
    "        \n",
    "        #DisplayPosition\n",
    "        loc1 = loc_data['DisplayPosition']\n",
    "    \n",
    "        #NavigationPosition\n",
    "        loc2 = loc_data['NavigationPosition'][0]\n",
    "    \n",
    "        #MapView\n",
    "        loc3A = loc_data['MapView']['TopLeft']\n",
    "        \n",
    "        loc3B = loc_data['MapView']['BottomRight']\n",
    "        \n",
    "        #Avg coordinates b/w Mapview TopLeft & Mapview BottomRight\n",
    "        loc4 = ((loc3A['Latitude'] + loc3B['Latitude']) / 2, (loc3A['Longitude'] + loc3B['Longitude']) / 2 )\n",
    "        \n",
    "        return [loc1['Latitude'], loc1['Longitude'], \n",
    "                loc2['Latitude'], loc2['Longitude'], \n",
    "                loc3A['Latitude'], loc3A['Longitude'],\n",
    "                loc3B['Latitude'], loc3B['Longitude'], \n",
    "                loc4[0], loc4[1]]\n",
    "    \n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All streetnames present in the dataframe\n",
    "street_names = list(df['street'].unique())\n",
    "\n",
    "# Remove from street_names list: nan value at index location 66, '' at index location 1, and 'onbekend' at index location 537\n",
    "del street_names[66]\n",
    "del street_names[1]\n",
    "del street_names[537]\n",
    "\n",
    "# Generate dictionary with street location and all corresponding locations\n",
    "street_locations = {street : get_location(street) for street in street_names}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all streets that API did NOT find location coordinates for\n",
    "failed_location = [street[0] for street in street_locations.items() if street[1] == None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove streets from street_locations dictionary that do not have any coordinates\n",
    "[street_locations.pop(street) for street in failed_location]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column order of coordinates (dis = display location, nav = navigation location, map_top = mapview topleft, map_bot = mapview bottomright, map_avg = mapview average)\n",
    "column_order = ['dis_lat', 'dis_long', 'nav_lat', 'nav_long', 'map_top_lat', 'map_top_long', 'map_bot_lat', 'map_bot_long', 'map_avg_lat', 'map_avg_long']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframe with streets as rows and coordinates as columns\n",
    "loc_df = pd.DataFrame.from_dict(street_locations, orient='index', columns=column_order)\n",
    "loc_df.reset_index(level=0, inplace=True)\n",
    "loc_df.rename(columns={'index':'street'}, inplace=True)\n",
    "loc_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dataframe into MySQL\n",
    "import sqlalchemy\n",
    "database_username = 'remote'\n",
    "database_password = 'EtrPCEc0jt'\n",
    "database_ip       = '165.22.199.122'\n",
    "database_name     = 'scavenger'\n",
    "database_connection = sqlalchemy.create_engine('mysql+mysqlconnector://{0}:{1}@{2}/{3}'.\n",
    "                                               format(database_username, database_password, \n",
    "                                                      database_ip, database_name))\n",
    "loc_df.to_sql(con=database_connection, name='locations', if_exists='replace')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
